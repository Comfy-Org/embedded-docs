> 本文檔由 AI 生成。如果您發現任何錯誤或有改進建議，歡迎貢獻！ [Edit on GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/SelfAttentionGuidance/zh-TW.md)

{heading_overview}

Self-Attention Guidance 節點透過在取樣過程中修改注意力機制，對擴散模型施加引導。它會從無條件去噪步驟中捕捉注意力分數，並利用這些分數建立模糊的引導圖來影響最終輸出。此技術透過利用模型自身的注意力模式來協助引導生成過程。

{heading_inputs}

| 參數 | 資料類型 | 必填 | 範圍 | 描述 |
|-----------|-----------|----------|-------|-------------|
| `model` | MODEL | 是 | - | 要應用自注意力引導的擴散模型 |
| `強度` | FLOAT | 否 | -2.0 至 5.0 | 自注意力引導效果的強度（預設值：0.5） |
| `模糊標準差` | FLOAT | 否 | 0.0 至 10.0 | 用於建立引導圖的模糊程度（預設值：2.0） |

{heading_outputs}

| 輸出名稱 | 資料類型 | 描述 |
|-------------|-----------|-------------|
| `model` | MODEL | 已應用自注意力引導的修改後模型 |

**注意：** 此節點目前處於實驗階段，並且在分塊批次處理方面存在限制。它只能儲存來自一次 UNet 呼叫的注意力分數，並且在較大的批次大小下可能無法正常運作。